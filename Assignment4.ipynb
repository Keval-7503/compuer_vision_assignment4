{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Assignment 4: Augmented Reality with PyTorch3D\n\n**Complete AR Pipeline Implementation**"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup - Clear cache and install dependencies\n!rm -rf compuer_vision_assignment4\n!git clone https://github.com/Keval-7503/compuer_vision_assignment4.git\n%cd compuer_vision_assignment4\n!git pull\n!pip install -q torch torchvision fvcore iopath\n!pip install -q \"git+https://github.com/facebookresearch/pytorch3d.git\""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Option 1: Run Demo Pipeline (Default)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run default demo\nfrom run_ar_pipeline import run_ar_pipeline\nresult = run_ar_pipeline()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n**Pipeline complete!** Results saved to `results/` folder.\n\nAll AR processing happens in the backend code (`src/` folder)."
  },
  {
   "cell_type": "markdown",
   "source": "## Option 2: Use Your Own Image",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Step 4: Run AR Pipeline\nfrom run_ar_pipeline import run_ar_pipeline_custom\n\nprint(\"Running AR pipeline...\")\nar_result, rendered, R, t, rmse = run_ar_pipeline_custom(\n    image_path=image_path,\n    image_points_2d=image_points_2d,\n    object_width=object_width,\n    object_height=object_height\n)\n\n# Display result\nresult_img = cv2.imread('results/custom_ar_result.png')\nresult_rgb = cv2.cvtColor(result_img, cv2.COLOR_BGR2RGB)\n\nplt.figure(figsize=(15, 10))\nplt.imshow(result_rgb)\nplt.title(\"Augmented Reality Result\")\nplt.axis('off')\nplt.show()\n\nprint(f\"\\nCamera Pose RMSE: {rmse:.4f} pixels\")\nprint(\"Saved to 'results/custom_ar_result.png'\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Step 3: Specify object dimensions\nprint(\"Enter the real-world dimensions of your planar object:\")\nprint(\"(e.g., A4 paper = 21cm x 29.7cm, Notebook = 20cm x 25cm)\")\nobject_width_cm = float(input(\"Width in cm: \"))\nobject_height_cm = float(input(\"Height in cm: \"))\n\nobject_width = object_width_cm / 100\nobject_height = object_height_cm / 100\nprint(f\"\\nObject size: {object_width}m x {object_height}m\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Step 2: Mark the 4 corners of your planar object\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Load and display image\nimg = cv2.imread(image_path)\nimg_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nheight, width = img.shape[:2]\n\nprint(f\"Image size: {width} x {height}\")\nprint(\"\\nInstructions:\")\nprint(\"Look at the image below and identify the 4 corners\")\nprint(\"Order: Top-Left, Top-Right, Bottom-Right, Bottom-Left\\n\")\n\nplt.figure(figsize=(12, 8))\nplt.imshow(img_rgb)\nplt.title(\"Identify the 4 corners of your planar object\")\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# Input corners\nprint(\"Enter corner coordinates (x, y):\")\ntl_x = int(input(\"Top-Left X: \"))\ntl_y = int(input(\"Top-Left Y: \"))\ntr_x = int(input(\"Top-Right X: \"))\ntr_y = int(input(\"Top-Right Y: \"))\nbr_x = int(input(\"Bottom-Right X: \"))\nbr_y = int(input(\"Bottom-Right Y: \"))\nbl_x = int(input(\"Bottom-Left X: \"))\nbl_y = int(input(\"Bottom-Left Y: \"))\n\nimage_points_2d = np.array([\n    [tl_x, tl_y], [tr_x, tr_y], [br_x, br_y], [bl_x, bl_y]\n], dtype=np.float32)\n\n# Show marked corners\nimg_marked = img_rgb.copy()\nfor i, pt in enumerate(image_points_2d):\n    pt_int = tuple(pt.astype(int))\n    cv2.circle(img_marked, pt_int, 10, (255, 0, 0), -1)\n    cv2.putText(img_marked, str(i+1), (pt_int[0]+15, pt_int[1]), \n                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 3)\n\nfor i in range(4):\n    pt1 = tuple(image_points_2d[i].astype(int))\n    pt2 = tuple(image_points_2d[(i+1)%4].astype(int))\n    cv2.line(img_marked, pt1, pt2, (0, 255, 0), 3)\n\nplt.figure(figsize=(12, 8))\nplt.imshow(img_marked)\nplt.title(\"Marked Corners\")\nplt.show()\nprint(\"Corners marked!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Step 1: Upload your image\nfrom google.colab import files\nimport shutil\n\nprint(\"Upload an image with a flat planar object (book, paper, notebook, etc.)\")\nuploaded = files.upload()\n\n# Save uploaded file\nimage_filename = list(uploaded.keys())[0]\nimage_path = f\"uploaded_{image_filename}\"\nshutil.move(image_filename, image_path)\nprint(f\"\\nImage saved as: {image_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}